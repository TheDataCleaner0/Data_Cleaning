{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "27ce77d1-0df0-41aa-b861-dafe96f0ff15",
      "cell_type": "markdown",
      "source": "# ðŸ§¼ Data Cleaning & Wrangling Project\n## 1. Project Overview\n- **Dataset**: dirty_cafe_sales.csv\n- **Source**: Kaggle Dataset - https://www.kaggle.com/datasets/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training/data\n- **Goal**: This primary objective of this project was to identify and rectify these issues, producing a clean, reliable dataset suitable for further analysis and visualization. The process involved initial data exploration, identification of quality problems, development and implementation of a cleaning strategy, and final validation of the results.\n\n",
      "metadata": {}
    },
    {
      "id": "167b569a-0962-4a90-a6a8-154aea535d52",
      "cell_type": "code",
      "source": "# Import necessary libararies\nimport pandas as pd\nimport numpy as np",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "70f88a9c-7415-4052-8ccf-45e7f2e4c9c7",
      "cell_type": "code",
      "source": "# Import Menu Item with Its Prices\nmenu_prices ={\n    \"Coffee\": 2.0,\n    \"Tea\": 1.5,\n    \"Sandwich\": 4.0,\n    \"Salad\": 5.0,\n    \"Cake\": 3.0,\n    \"Cookie\": 1.0,\n    \"Smoothie\": 4.0,\n    \"Juice\": 3.0\n}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f4905e2c-b38f-4c74-8407-8ce5c0b54897",
      "cell_type": "code",
      "source": "# Load Dataset\ndf = pd.read_csv('dirty_cafe_sales.csv')  # Change to your file\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "664947d4-660c-4a64-a6c9-3ed4ee36a0ac",
      "cell_type": "markdown",
      "source": "## 2. Initial Data Exploration",
      "metadata": {}
    },
    {
      "id": "b84de2d1-d374-4c2f-8cc0-e7be0396aa43",
      "cell_type": "code",
      "source": "print(\"Rows:\", df.shape[0], \"Columns:\", df.shape[1]) # we have 8 columns and 10000 rows of data in the dataset\ndf.info() # transaction ID is unique idetifier of each data entry",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "16e005f2-b5d4-43bb-bc2b-e06042fc1373",
      "cell_type": "code",
      "source": "df.describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "51afdcf8-0fc2-45db-90aa-a7273f313cfe",
      "cell_type": "code",
      "source": "df.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "36d62b3a-1429-4202-bb80-659363a02942",
      "cell_type": "markdown",
      "source": "## 3. Data Cleaning Steps",
      "metadata": {}
    },
    {
      "id": "605eaf8b-8c41-4462-9d4c-658ee7ca4840",
      "cell_type": "markdown",
      "source": "### 3.1 Convert Data Types",
      "metadata": {}
    },
    {
      "id": "9618ddcc-98ed-4c2d-9ad9-2bf47c7e1750",
      "cell_type": "code",
      "source": "# Transcation ID is the unique identifier, so no change is made for it.\n# Item - remove whitespace\ndf['Item'] = df['Item'].str.strip() \n\n# Quantity, Price Per Unit, Total Spent should be converted to numeric\ndf['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\ndf['Price Per Unit'] = pd.to_numeric(df['Price Per Unit'], errors='coerce')\ndf['Total Spent'] = pd.to_numeric(df['Total Spent'], errors='coerce')\n\n# transaction date should be converted to date\ndf['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "42b0b1df-3091-4f73-bb4f-02eaefd6ce71",
      "cell_type": "markdown",
      "source": "### 3.2 Handling Invalid/Inconsistent Values",
      "metadata": {}
    },
    {
      "id": "cd0e9947-27a7-478d-bb42-99296dde042e",
      "cell_type": "code",
      "source": "df.replace(['ERROR', 'UNKNOWN'], np.nan, inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ee62e24b-a69e-42b5-a5c6-243e7a3edc34",
      "cell_type": "code",
      "source": "item_mode = df['Item'].mode()[0]\ndf['Item'] = df['Item'].fillna(item_mode)\n\npayment_mode = df[\"Payment Method\"].mode()[0]\ndf[\"Payment Method\"] = df[\"Payment Method\"].fillna(payment_mode)\n\nlocation_mode = df[\"Location\"].mode()[0]\ndf[\"Location\"] = df[\"Location\"].fillna(location_mode)\n\ndate_mode = df[\"Transaction Date\"].mode()[0]\ndf[\"Transaction Date\"] = df[\"Transaction Date\"].fillna(date_mode)\n\nquantity_median = df['Quantity'].median()\ndf['Quantity'] = df['Quantity'].fillna(quantity_median)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3e554696-cf98-44b7-bb22-a2acaf6377e6",
      "cell_type": "code",
      "source": "# fill in the empty values in price per unit based on the items\ndef impute_price(row):\n    if pd.isna(row['Price Per Unit']):\n        item = row['Item']\n        if item in menu_prices:\n            return menu_prices[item]\n        else:\n            price_median = df['Price Per Unit'].median()\n            return price_median\n    return row['Price Per Unit']\n\ndf['Price Per Unit'] = df.apply(impute_price, axis=1)\n\ndf['Total Spent'] = df['Quantity'] * df['Price Per Unit']\n\ndf.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6f261295-7438-4e13-8c91-86977141a91b",
      "cell_type": "markdown",
      "source": "### 3.3 Remove Duplicates",
      "metadata": {}
    },
    {
      "id": "19e41360-fdbe-4720-9db9-be60a859d559",
      "cell_type": "code",
      "source": "initial_rows = len(df)\ndf.drop_duplicates(subset=['Transaction ID'], keep='first', inplace=True)\nduplicates_removed = initial_rows - len(df)\nif duplicates_removed > 0:\n    print(\"Removed {duplicates_removed} duplicate rows based on 'Transaction ID'.\")\nelse:\n    print(\"No duplicate 'Transaction ID' found.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a0e9e171-2bda-43fb-b40d-fb547d55f09b",
      "cell_type": "markdown",
      "source": "## 4. Post-Cleaning Checks",
      "metadata": {}
    },
    {
      "id": "aeb48825-5b2e-488b-b2a0-31ef0ebbb1b2",
      "cell_type": "code",
      "source": "df.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c8f1da8d-20f7-4c17-953a-6228f6b482e5",
      "cell_type": "markdown",
      "source": "## 5. Summary & Next Steps\nThe data cleaning process successfully addressed the identified quality issues in the original dirty_cafe_sales.csv dataset. Missing values, incorrect data types, invalid entries, and calculation inconsistencies were handled according to the defined plan. Validation confirmed that the resulting dataset, cleaned_cafe_sales.csv, is complete, consistent, and has appropriate data types.\n**This cleaned dataset is now suitable for reliable downstream analysis, visualization, or machine learning tasks**",
      "metadata": {}
    },
    {
      "id": "c26285f5-aa85-4b45-8b32-7b5e96b5201e",
      "cell_type": "code",
      "source": "# save cleaned data\ndf.to_csv(\"cleaned_cafe_sales.csv\", index=False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}